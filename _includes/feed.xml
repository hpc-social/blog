<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en-US"><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="https://hpc.social/personal-blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://hpc.social/personal-blog/" rel="alternate" type="text/html" hreflang="en-US" /><updated>2026-01-22T20:52:28-07:00</updated><id>https://hpc.social/personal-blog/feed.xml</id><title type="html">hpc.social - Aggregated Personal Blog</title><subtitle>Shared personal experiences and stories</subtitle><author><name>hpc.social</name><email>info@hpc.social</email></author><entry><title type="html">Quoting Charity Majors</title><link href="https://hpc.social/personal-blog/2026/quoting-charity-majors/" rel="alternate" type="text/html" title="Quoting Charity Majors" /><published>2026-01-19T17:47:51-07:00</published><updated>2026-01-19T17:47:51-07:00</updated><id>https://hpc.social/personal-blog/2026/quoting-charity-majors</id><content type="html" xml:base="https://hpc.social/personal-blog/2026/quoting-charity-majors/"><![CDATA[<p>Charity‚Äôs latest post, <em><a href="https://charity.wtf/2026/01/19/bring-back-ops-pride-xpost/">Bring back ops pride</a></em>, is an excellent discussion (rant?) on the importance of operations for software systems and why it‚Äôs a bad idea to try and pretend it isn‚Äôt a real concern, or make conventional application teams do the work in addition to their regular job.</p>

<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p>‚ÄúOperations‚Äù is not a dirty word, a synonym for toil, or a title for people who can‚Äôt write code. May those who shit on ops get the operational outcomes they deserve.</p>

</blockquote>

<p>You should absolutely go read the <a href="https://charity.wtf/2026/01/19/bring-back-ops-pride-xpost/">full piece</a>, as well as Charity‚Äôs earlier post on the Honeycomb blog: <em><a href="https://www.honeycomb.io/blog/you-had-one-job-why-twenty-years-of-devops-has-failed-to-do-it">You had one job: Why twenty years of DevOps has failed to do it</a></em>. </p>

<p>Below find several pull quotes from the post itself, because there were just too many to choose from.</p>

<p><span id="more-430"></span></p>

<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p>The difference between ‚Äúdev‚Äù and ‚Äúops‚Äù is not about whether or not you can write code. Dude, it‚Äôs 2026:&nbsp;<strong>everyone writes software</strong>.</p>




<p>The difference between dev and ops is a separation of concerns.</p>

</blockquote>

<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p>The hardest technical challenges and the long, stubborn tail of intractable problems have&nbsp;<em>always</em>&nbsp;been on the infrastructure side.&nbsp;<strong>That‚Äôs why we work&nbsp;<em>so hard</em>&nbsp;to try not to have them</strong>‚Äîto solve them by partnerships, cloud computing, open source, etc.&nbsp;<em>Anything</em>&nbsp;is better than trying to build them again, starting over from scratch. We know the cost of new code in our bones.</p>




<p>As I have said a thousand times: the closer you get to laying bits down on disk, the more conservative (and afraid) you should be.</p>

</blockquote>

<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p>The difference between dev and ops isn‚Äôt about writing code or not. But there&nbsp;<em>are</em>&nbsp;differences. In perspective, priorities, and (often) temperament.</p>




<p>I touched on a number of these in&nbsp;<a href="https://www.honeycomb.io/blog/you-had-one-job-why-twenty-years-of-devops-has-failed-to-do-it">the article I just wrote on feedback loops</a>, so I‚Äôm not going to repeat myself here.</p>




<p>The biggest difference I did&nbsp;<em>not</em>&nbsp;mention is that they have different relationships with resources and definitions of success.</p>




<p>Infrastructure is a cost center. You aren‚Äôt going to make more money if you give ten laptops to everyone in your company, and you aren‚Äôt going to make more money by over-spending on infrastructure, either. Great operations engineers and architects never forget that&nbsp;<strong>cost is a first class citizen</strong>&nbsp;of their engineering decisions.</p>

</blockquote>

<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p>Operational rigor and excellence are not, how shall I say this‚Ä¶not yet something you can take for granted in the tech industry. The most striking thing about the 2025 DORA report was that the&nbsp;<em>majority of companies</em>&nbsp;report that AI is just adding more chaos to a system already defined by chaos. In other words, most companies are bad at ops.</p>

</blockquote>]]></content><author><name>Thinking Out Loud</name></author><category term="ajdecon" /><summary type="html"><![CDATA[Charity‚Äôs latest post, Bring back ops pride, is an excellent discussion (rant?) on the importance of operations for software systems and why it‚Äôs a bad idea to try and pretend it isn‚Äôt a real concern, or make conventional application teams do the work in addition to their regular job.]]></summary></entry><entry><title type="html">Quoting Nicholas Carlini</title><link href="https://hpc.social/personal-blog/2026/quoting-nicholas-carlini/" rel="alternate" type="text/html" title="Quoting Nicholas Carlini" /><published>2026-01-18T17:07:12-07:00</published><updated>2026-01-18T17:07:12-07:00</updated><id>https://hpc.social/personal-blog/2026/quoting-nicholas-carlini</id><content type="html" xml:base="https://hpc.social/personal-blog/2026/quoting-nicholas-carlini/"><![CDATA[<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p>Because when the people training these models justify why they&#8217;re worth it, they appeal to pretty extreme outcomes. When Dario Amodei wrote his essay&nbsp;<a href="https://www.darioamodei.com/essay/machines-of-loving-grace">Machines of Loving Grace</a>, he wrote that he sees the benefits as being extraordinary: &#8220;Reliable prevention and treatment of nearly all natural infectious disease &#8230; Elimination of most cancer &#8230; Prevention of Alzheimer‚Äôs &#8230; Improved treatment of most other ailments &#8230; Doubling of the human lifespan.&#8221; These are the benefits that the CEO of Anthropic uses to justify his belief that LLMs are worth it. If you think that these risks sound fanciful, then I might encourage you to consider what benefits you see LLMs as bringing, and then consider if you think the risks&nbsp;are worth it.</p>

</blockquote>

<p>From Carlini‚Äôs recent talk/article on <em><a href="https://nicholas.carlini.com/writing/2025/are-llms-worth-it.html">Are large language models worth it?</a></em></p>

<p>The entire article is well worth reading, but I was struck by this bit near the end. LLM researchers often dismiss (some of) the risks of these models as fanciful. But many of the benefits touted by the labs sound just as fanciful!</p>

<p>When we‚Äôre evaluating the worth of this research, it‚Äôs a good idea to be consistent about how realistic ‚Äî or how ‚Äúgalaxy brain‚Äù ‚Äî you want to be, with both risks and benefits.</p>]]></content><author><name>Thinking Out Loud</name></author><category term="ajdecon" /><summary type="html"><![CDATA[Because when the people training these models justify why they&#8217;re worth it, they appeal to pretty extreme outcomes. When Dario Amodei wrote his essay&nbsp;Machines of Loving Grace, he wrote that he sees the benefits as being extraordinary: &#8220;Reliable prevention and treatment of nearly all natural infectious disease &#8230; Elimination of most cancer &#8230; Prevention of Alzheimer‚Äôs &#8230; Improved treatment of most other ailments &#8230; Doubling of the human lifespan.&#8221; These are the benefits that the CEO of Anthropic uses to justify his belief that LLMs are worth it. If you think that these risks sound fanciful, then I might encourage you to consider what benefits you see LLMs as bringing, and then consider if you think the risks&nbsp;are worth it.]]></summary></entry><entry><title type="html">Robin Sloan- AGI is already here!</title><link href="https://hpc.social/personal-blog/2026/robin-sloan-agi-is-already-here/" rel="alternate" type="text/html" title="Robin Sloan- AGI is already here!" /><published>2026-01-18T16:50:37-07:00</published><updated>2026-01-18T16:50:37-07:00</updated><id>https://hpc.social/personal-blog/2026/robin-sloan-agi-is-already-here-</id><content type="html" xml:base="https://hpc.social/personal-blog/2026/robin-sloan-agi-is-already-here/"><![CDATA[<p>In Robin Sloan‚Äôs ‚Äúpop-up newsletter‚Äù <em>Winter Garden</em>, <a href="https://www.robinsloan.com/winter-garden/agi-is-here/">he argues that artificial general intelligence has been with us since the development of GPT-3</a>:</p>

<p><span id="more-419"></span></p>

<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p>The trick is to read plainly.</p>




<p>The key word in Artificial General Intelligence is General.‚ÄÇThat‚Äôs the word that makes this AI unlike every other AI: because every other AI was trained for a particular purpose and, &amp; even if it achieved it in spectacular fashion, did not do anything else.‚ÄÇConsider landmark models across the decades: the Mark I&nbsp;Perceptron, LeNet, AlexNet, AlphaGo, AlphaFold‚Äâ‚Ä¶‚Äâthese systems were all different, but all alike in this way.</p>




<p>Language models were trained for a purpose, too‚Äâ‚Ä¶‚Äâbut, surprise: the mechanism &amp; scale of that training did something new: opened a wormhole, through which a vast field of action &amp; response could be reached.‚ÄÇTowering libraries of human writing, drawn together across time &amp; space, all the dumb reasons for it‚Äâ‚Ä¶‚Äâthat‚Äôs rich fuel, if you can hold it all in your head.</p>




<p>It‚Äôs important to emphasize that the open-ended capability of these big models was a genuine surprise, even to their custodians.‚ÄÇOnce understood, the opportunity was quickly grasped‚Äâ‚Ä¶‚Äâbut the magnitude of that initial whoa?! is still ringing the bell of this century.</p>




<p>I‚Äôm extreme in this regard: I&nbsp;think 2020‚Äôs <a href="https://arxiv.org/abs/2005.14165?utm_source=Robin_Sloan_sent_me">Language Models are Few-Shot Learners</a> marks the AGI moment.‚ÄÇIn that paper, OpenAI researchers demonstrated that GPT-3‚Ää‚Äî‚Ääat that time, the biggest model of its kind ever trained‚Ää‚Äî‚Ääperformed better on a wide range of linguistic tasks than models trained for those tasks specifically.‚ÄÇA more direct title might have been: This Thing Can Do It All?!</p>

</blockquote>

<p>‚ÄúAGI‚Äù is such a misused, ill-defined term that I honestly don‚Äôt find it too useful‚Ä¶ but it‚Äôs hard to argue with Sloan‚Äôs argument here! Certainly if you showed current LLMs to someone from 20 years ago, or even 10, they‚Äôd seem like wild science fiction.</p>

<p>It also reminds me of a quote from Asimov on the definition of ‚Äúartificial intelligence‚Äù and how the goal posts move as new achievements are retrospectively deemed as ‚Äúnot AI‚Äù:</p>

<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p>[artificial intelligence is] a phrase that we use for any device that does things which, in the past, we have associated only with human intelligence</p>

</blockquote>

<p>(via <a href="https://nicholas.carlini.com/writing/2025/are-llms-worth-it.html">Nicholas Carlini</a>)</p>

<p>So. Do we have AGI? Do we even meaningfully have AI? What would we have to see for the general consensus to agree they had been achieved?</p>

<p>Anyway, they are mostly marketing terms at this point. But it can still be interesting to think about them.</p>

<hr class="wp-block-separator has-alpha-channel-opacity" />

<p>Thoughts from a dog walk listening to the Sloan article using ElevenReader.</p>

<figure class="wp-block-image size-large"><img class="wp-image-421" height="768" src="https://thinking.ajdecon.org/wp-content/uploads/2026/01/img_3019-1024x768.jpg" width="1024" /><figcaption class="wp-element-caption">Benny is unimpressed with being asked to pose during his walk</figcaption></figure>]]></content><author><name>Thinking Out Loud</name></author><category term="ajdecon" /><summary type="html"><![CDATA[In Robin Sloan‚Äôs ‚Äúpop-up newsletter‚Äù Winter Garden, he argues that artificial general intelligence has been with us since the development of GPT-3:]]></summary></entry><entry><title type="html">tailscale</title><link href="https://hpc.social/personal-blog/2026/tailscale/" rel="alternate" type="text/html" title="tailscale" /><published>2026-01-12T05:13:12-07:00</published><updated>2026-01-12T05:13:12-07:00</updated><id>https://hpc.social/personal-blog/2026/tailscale</id><content type="html" xml:base="https://hpc.social/personal-blog/2026/tailscale/"><![CDATA[<p><a href="https://bsky.app/profile/buttplug.engineer/post/3mc6qyarp2c2m">Some discussion on bsky</a> of the usefulness of Tailscale, and I‚Äôll just note here how very handy it is for running a personal homelab that includes cloud instances. As well as just having lab connectivity from a laptop or phone on the go!</p>

<p>Services I run over Tailscale, just for myself, include:</p>

<ul class="wp-block-list">
<li>An RSS feed reader</li>



<li>A personal git forge</li>



<li>An IRC bouncer</li>



<li>A (poorly maintained) wiki</li>



<li>JupyterLab</li>



<li>Open WebUI for playing with local LLMs on a GPU workstation</li>



<li>SSH to a powerful workstation, hosted at home but without complex configs</li>
</ul>

<p>And probably a few things I‚Äôve forgotten! It‚Äôs really just very neat. Sure I could do it all with manual Wireguard configs. But Tailscale just makes the underlying primitive much more ergonomic.</p>]]></content><author><name>Thinking Out Loud</name></author><category term="ajdecon" /><summary type="html"><![CDATA[Some discussion on bsky of the usefulness of Tailscale, and I‚Äôll just note here how very handy it is for running a personal homelab that includes cloud instances. As well as just having lab connectivity from a laptop or phone on the go!]]></summary></entry><entry><title type="html">Quoting antirez on AI</title><link href="https://hpc.social/personal-blog/2026/quoting-antirez-on-ai/" rel="alternate" type="text/html" title="Quoting antirez on AI" /><published>2026-01-12T03:44:08-07:00</published><updated>2026-01-12T03:44:08-07:00</updated><id>https://hpc.social/personal-blog/2026/quoting-antirez-on-ai</id><content type="html" xml:base="https://hpc.social/personal-blog/2026/quoting-antirez-on-ai/"><![CDATA[<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<pre class="wp-block-preformatted">Anyway, back to programming. I have a single suggestion for you, my friend. Whatever you believe about what the Right Thing should be, you can't control it by refusing what is happening right now. Skipping AI is not going to help you or your career. Think about it. Test these new tools, with care, with weeks of work, not in a five minutes test where you can just reinforce your own beliefs. Find a way to multiply yourself, and if it does not work for you, try again every few months.<br /><br />Yes, maybe you think that you worked so hard to learn coding, and now machines are doing it for you. But what was the fire inside you, when you coded till night to see your project working? It was building. And now you can build more and better, if you find your way to use AI effectively. The fun is still there, untouched</pre>
</blockquote>

<p>From <em><a href="https://antirez.com/news/158">Don‚Äôt fall into the anti-AI hype</a></em></p>]]></content><author><name>Thinking Out Loud</name></author><category term="ajdecon" /><summary type="html"><![CDATA[Anyway, back to programming. I have a single suggestion for you, my friend. Whatever you believe about what the Right Thing should be, you can't control it by refusing what is happening right now. Skipping AI is not going to help you or your career. Think about it. Test these new tools, with care, with weeks of work, not in a five minutes test where you can just reinforce your own beliefs. Find a way to multiply yourself, and if it does not work for you, try again every few months.Yes, maybe you think that you worked so hard to learn coding, and now machines are doing it for you. But what was the fire inside you, when you coded till night to see your project working? It was building. And now you can build more and better, if you find your way to use AI effectively. The fun is still there, untouched]]></summary></entry><entry><title type="html">Latency-critical Linux task scheduling for gaming</title><link href="https://hpc.social/personal-blog/2026/latency-critical-linux-task-scheduling-for-gaming/" rel="alternate" type="text/html" title="Latency-critical Linux task scheduling for gaming" /><published>2026-01-10T17:26:29-07:00</published><updated>2026-01-10T17:26:29-07:00</updated><id>https://hpc.social/personal-blog/2026/latency-critical-linux-task-scheduling-for-gaming</id><content type="html" xml:base="https://hpc.social/personal-blog/2026/latency-critical-linux-task-scheduling-for-gaming/"><![CDATA[<p><em><a href="https://lwn.net/Articles/1051430/">LWN</a></em> has an excellent article up on the ‚Äúlatency-criticality aware virtual deadline‚Äù (LAVD) scheduler, from a talk at the <em>Linux Plumbers Conference</em> in December.</p>

<p>In particular, I appreciate the detailed discussion of using different profilers and performance-analysis tools at different levels to determine how to optimize scheduling to improve two key goals: providing high average FPS while keeping 99th-percentile FPS as low as possible, e.g. to prevent UI stuttering. Optimizing for battery usage is also important, as the Steam Deck was one of the main targets for this work.</p>

<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p>The key finding that came out of his analysis is perhaps somewhat obvious: a single high-level action, such as moving a character on-screen and emitting a sound based on a key-press event, requires that many tasks work together. Some of the tasks are threads in the game process, but others are not because they are in the game engine, kernel, and device drivers; there are often 20 or 30 tasks in a chain that all need to collaborate. Finding tasks with a high waker or wakee frequency and prioritizing them is the basis of the LAVD scheduling policy.</p>

</blockquote>

<p>As always with <em>LWN</em> there‚Äôs good coverage not only of the talk itself, but also the Q&amp;A following the session and ideas from the audience on tooling and other improvements.</p>

<p><em><a href="https://www.phoronix.com/news/Meta-SCX-LAVD-Steam-Deck-Server">Phoronix</a></em> also covered a different talk from the same conference (I think) on how Meta is using the LAVD scheduler as the basis for a new default scheduler used on their fleet. </p>

<p>I haven‚Äôt had a chance to watch this talk yet (<a href="https://youtu.be/KFItEHbFEwg?si=62Hsyr9ydHcOVu9b">video</a> linked from the article) but I‚Äôm very interested in the idea that the same concepts might be useful to a hyper scaler as well as a device like a Steam Deck.</p>]]></content><author><name>Thinking Out Loud</name></author><category term="ajdecon" /><summary type="html"><![CDATA[LWN has an excellent article up on the ‚Äúlatency-criticality aware virtual deadline‚Äù (LAVD) scheduler, from a talk at the Linux Plumbers Conference in December.]]></summary></entry><entry><title type="html">Orchestrating Hybrid Quantum‚ÄìClassical Workflows with IBM LSF- Inside the SQD Workflow Demo at SC25</title><link href="https://hpc.social/personal-blog/2026/orchestrating-hybrid-quantum-classical-workflows-with-ibm-lsf-inside-the-sqd-workflow-demo-at-sc25/" rel="alternate" type="text/html" title="Orchestrating Hybrid Quantum‚ÄìClassical Workflows with IBM LSF- Inside the SQD Workflow Demo at SC25" /><published>2026-01-08T14:22:59-07:00</published><updated>2026-01-08T14:22:59-07:00</updated><id>https://hpc.social/personal-blog/2026/orchestrating-hybrid-quantum-classical-workflows-with-ibm-lsf-inside-the-sqd-workflow-demo-at-sc25</id><content type="html" xml:base="https://hpc.social/personal-blog/2026/orchestrating-hybrid-quantum-classical-workflows-with-ibm-lsf-inside-the-sqd-workflow-demo-at-sc25/"><![CDATA[<p>As we enter 2026, it seems that SC25 is far off in our rearview mirror. But it&rsquo;s only been a bit over a month since the HPC world converged on St. Louis, Missouri for the annual <a href="https://sc25.supercomputing.org/">Supercomputing 2025</a> (SC25) event. SC25 signaled one emerging trend: the exploration of hybrid workflows combining quantum and classical computing, offering a look at how these technologies can work synergistically over time. This was indeed the main topic of the 1st Annual Workshop on Large-Scale Quantum-Classical Computing, a workshop which I found to be very insightful.</p>

<p>At the IBM booth, we showcased how <a href="https://www.ibm.com/products/hpc-workload-management">IBM LSF</a> can schedule and orchestrate a hybrid quantum‚Äìclassical workflow across IBM Quantum systems and classical x86 compute.  The demo featured the Sample-based Quantum Diagonalization (SQD) workflow, to estimate the ground-state energy of a Hamiltonian representing a molecular system. SQD is part of the <a href="https://quantum.cloud.ibm.com/docs/en/guides/qiskit-addons-sqd">IBM Qiskit add-ons</a>.</p>

<p>Before diving into the details on what was demonstrated at SC25, and how LSF was used to manage the workflow, I would like to acknowledge that this work was supported by the Hartree Center for Digital Innovation, a collaboration between UKRI-STFC and IBM. The demonstration was created in close collaboration with Vadim Elisseev and Ritesh Krishna from IBM Research, alongside G√°bor Samu and Michael Spriggs from IBM. Additionally, this post does not aim to provide an in-depth look at SQD itself. Rather the focus is on how LSF can manage hybrid quantum-classical workflows across a heterogeneous environment comprised of both quantum and classical resources.</p>

<p><strong>Hybrid workflows are not new</strong></p>

<p>For three decades, we have seen the use of accelerators in HPC to drive performance‚Äîfrom GPUs to FPGAs and other specialized architectures. Effective scheduling of tasks in these heterogeneous environments has always been a key consideration for efficiency, scalability‚Äîand to maximize the ROI in commercial HPC environments. As resource topologies grow more complex, scheduling must account for characteristics such as connectivity, latency, and dependency constraints across increasingly diverse infrastructures. Quantum Processors (QPUs) are now making their appearance as complementary resources within HPC workflows, aim at challenges such as specific optimization problems, many-body physics and quantum chemistry.</p>

<p><strong>Demo details</strong></p>

<p>The IBM LSF cluster was deployed on IBM Cloud using the LSF Deployable Architecture, which rapidly deploys and configures a ready-to-use HPC environment. IBM Research provided integration components for LSF in the form of esub and jobstarter scripts. These scripts enable LSF to query the cloud-based IBM Quantum Platform to determine which QPUs are available for a given user account and meet the qubit requirements specified at job submission. The list of eligible QPUs is then sorted by queue length, and the system with the shortest queue is selected as the target for the quantum circuit. These integration scripts (esub and jobstarter) are intended to be made open source at a later time.</p>

<p>The LSF environment was deployed on IBM Cloud using the <a href="https://cloud.ibm.com/catalog/architecture/deploy-arch-ibm-hpc-lsf-1444e20a-af22-40d1-af98-c880918849cb-global">LSF Deployable Architecture</a> v3.1.0:</p>

<ul>
<li>LSF 10.1.0.15</li>
<li>RHEL 8.10</li>
<li>IBM Cloud profile bx2-16x64 (compute hosts)</li>
</ul>
<p>The IBM Qiskit package versions used:</p>

<ul>
<li>qiskit v2.2.1</li>
<li>qiskit-addon-sqd v0.12.0</li>
<li>qiskit-ibm-runtime v0.43.0</li>
</ul>
<p>The SQD Python program is available as part of the IBM Qiskit Add-ons (see details here). For this demonstration, the original monolithic SQD script was refactored into four smaller Python programs‚Äîeach representing a distinct step in the workflow. These steps map directly to LSF jobs, enabling orchestration of the workflow across the quantum and classical HPC resources as shown in the architecture diagram (Figure 1):</p>

<ul>
<li><strong>Stage 1</strong> map the inputs to a quantum problem.</li>
<li><strong>Stage 2</strong> optimizes the problem for quantum hardware execution‚Äîthis is where the circuit is transpiled and optimized for the target QPU</li>
<li><strong>Stage 3</strong> executes the circuit on the QPU using Qiskit primitives</li>
<li><strong>Stage 4</strong> performs post-processing and returns the result in the desired classical format</li>
</ul>
<p><figure><img src="https://www.gaborsamu.com/images/figure1_lsfqc.png" />
</figure>

<em>Figure 1 LSF hybrid quantum-classical workflow demo (Vadim Elisseev, IBM Research)</em></p>

<p>For this demonstration, we used IBM LSF Application Center‚Äîa web-based interface for job submission and management. LSF Application Center supports application templates, which simplify job submission by providing predefined forms. Templates were created for both the SQD workflow and the Jupyter Notebook application, which is used to visualize the workflow results.</p>

<p><strong>Demo execution steps</strong></p>

<ul>
<li>We start by using the SQD template to submit an instance of the SQD workflow (Figure 2) which is used to calculate an approximate ground-energy state of the nitrogen molecule (N2). The submission form is customized to let users specify the script for each step of the workflow and specify the desired number of qubits required on the QPU for the quantum circuit. This parameter is used by LSF to select the appropriate quantum system from the available resources. Note that jobs are submitted to LSF with a done dependency condition, ensuring that each stage runs only after the previous one completes successfully. Stage 2 begins after Stage 1, Stage 3 follows Stage 2, and Stage 4 executes once Stage 3 has finished</li>
</ul>
<p><figure><img src="https://www.gaborsamu.com/images/figure2a_lsfqc.png" />
</figure>

<em>Figure 2 LSF Application Center SQD submission form</em></p>

<ul>
<li>Next, we submit an instance of the Jupyter Notebook to monitor the workflow initiated in Step 1. This notebook is designed for this demonstration to visualize the status of each workflow step, displaying results as they successfully complete. Figure 3 shows the Jupyter submission form.</li>
</ul>
<p><figure><img src="https://www.gaborsamu.com/images/figure3a_lsfqc.png" />
</figure>

<em>Figure 3 LSF Application Center Jupyter Notebook submission form</em></p>

<ul>
<li>The Workload view in the LSF Application Center can be used to monitor the progress of each job within the workflow. Additionally, the Jupyter Notebook instance can be accessed here via the provided hyperlink. Figure 4 shows the workload view in LSF Application Center. This shows a list of jobs in the LSF system.</li>
</ul>
<p><figure><img src="https://www.gaborsamu.com/images/figure4a_lsfqc.png" />
</figure>

<em>Figure 4 LSF Application Center workload view</em></p>

<ul>
<li>As each stage of the SQD workflow completes, the Jupyter Notebook displays the corresponding output in new browser tabs. This includes qubit coupling maps for the QPUs available on the IBM Quantum Platform for the specific account, a diagram of the circuit mapped to the selected QPU, readings from the QPU, and a plot of the estimated ground-state energy of the N2 molecule.</li>
</ul>
<p><figure><img src="https://www.gaborsamu.com/images/figure5_lsfqc.png" />
</figure>

<em>Figure 5 Output from each step of the SQD workflow (Vadim Elisseev, IBM Research)</em></p>

<ul>
<li>Given that demo environment was built using the LSF Deployable Architecture, IBM Cloud Monitoring is automatically configured. It provides a dashboard for the underlying cloud infrastructure, including detailed hardware metrics. In addition, an LSF Dashboard is available through IBM Cloud Monitoring, showing overall cluster metrics such as total jobs, job status, and queue distribution, along with scheduler performance trends over time. IBM Cloud Monitoring infrastructure view and LSF dashboard are shown in Figure 5.</li>
</ul>
<p><figure><img src="https://www.gaborsamu.com/images/figure6_lsfqc.png" />
</figure>

<em>Figure 6 IBM Cloud Monitoring: Infrastructure view, and LSF dashboard</em></p>

<p>A video recording of the end-to-end demonstration can be found <a href="https://community.ibm.com/community/user/viewdocument/demonstration-of-managing-hybrid-qu?CommunityKey=74d589b7-7276-4d70-acf5-0fc26430c6c0&amp;tab=librarydocuments">here</a>.</p>

<p><strong>Conclusions</strong></p>

<p>This demo marked a milestone by demonstrating that IBM Spectrum LSF can seamlessly orchestrate quantum and classical compute resources for a unified workflow. This example demonstrates a practical approach to integrating quantum capabilities into an existing HPC environment running IBM LSF.</p>

<p>This capability lays the foundation for hybrid computing pipelines that integrate emerging quantum hardware into established HPC environments. As organizations adopt these architectures and tools mature, we can expect production-grade workflows tackling complex problems across domains. The future of HPC is not a choice between classical or quantum‚Äîit is their convergence, working together to unlock new computational possibilities.</p>

<p>The topic of scheduling for hybrid quantum-classical environments will be the subject of an upcoming paper &ldquo;On Topological Aspects of Workflows Scheduling on Hybrid Quantum - High Performance Computing Systems&rdquo; by Vadim Elisseev, Ritesh Krishna, Vasileios Kalantzis, M. Emre Sahin and G√°bor Samu.</p>]]></content><author><name>Ramblings of a supercomputing enthusiast.</name></author><category term="gaborsamu" /><summary type="html"><![CDATA[As we enter 2026, it seems that SC25 is far off in our rearview mirror. But it&rsquo;s only been a bit over a month since the HPC world converged on St. Louis, Missouri for the annual Supercomputing 2025 (SC25) event. SC25 signaled one emerging trend: the exploration of hybrid workflows combining quantum and classical computing, offering a look at how these technologies can work synergistically over time. This was indeed the main topic of the 1st Annual Workshop on Large-Scale Quantum-Classical Computing, a workshop which I found to be very insightful.]]></summary></entry><entry><title type="html">‚ÄúMy Cousin Vinny‚Äù as an LLM benchmark</title><link href="https://hpc.social/personal-blog/2026/my-cousin-vinny-as-an-llm-benchmark/" rel="alternate" type="text/html" title="‚ÄúMy Cousin Vinny‚Äù as an LLM benchmark" /><published>2026-01-05T04:04:31-07:00</published><updated>2026-01-05T04:04:31-07:00</updated><id>https://hpc.social/personal-blog/2026/-my-cousin-vinny-as-an-llm-benchmark</id><content type="html" xml:base="https://hpc.social/personal-blog/2026/my-cousin-vinny-as-an-llm-benchmark/"><![CDATA[<p>Mike Caulfield wrote a <a href="https://mikecaulfield.substack.com/p/notes-towards-a-narrative-llm-benchmark">very thorough and quite entertaining article</a> about posing the following question to ChatGPT:</p>

<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p>What were Marisa Tomei‚Äôs most famous quotes from My Cousin Vinny and what was the context?</p>

</blockquote>

<p>Depending on the model selected, the answers to this varied from hilariously wrong, to plausible-but-flawed, to accurate. </p>

<p>Interestingly, substantial test-time compute (‚Äúthinking time‚Äù) seems to be necessary to do a good job here, despite the easy availability online of famous quotes, plot summaries, and even the script. While the fast-response models available for free were prone to hallucinate. </p>

<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p>At the same time I was struck just how&nbsp;<em>much</em> reasoning time needed to be expended to get this task right. It‚Äôs possible that&nbsp;<em>My Cousin Vinny</em>&nbsp;is uniquely hard to parse, but I don‚Äôt think that is the case. I‚Äôve tried this with a half dozen other films and the pattern seems to hold. If it‚Äôs true that a significant amount of similar film contextualization tasks are solvable with test-time compute but require extensive compute to get it right, it seems to me this could be the basis of a number of useful benchmarks.</p>

</blockquote>

<p>The <a href="https://mikecaulfield.substack.com/p/notes-towards-a-narrative-llm-benchmark">full article</a> is well-worth reading, and not only because it discusses <em>My Cousin Vinny</em> in substantial detail (great movie).</p>]]></content><author><name>Thinking Out Loud</name></author><category term="ajdecon" /><summary type="html"><![CDATA[Mike Caulfield wrote a very thorough and quite entertaining article about posing the following question to ChatGPT:]]></summary></entry><entry><title type="html">Podcasts and blogs I‚Äôm following in early 2026</title><link href="https://hpc.social/personal-blog/2026/podcasts-and-blogs-i-m-following-in-early-2026/" rel="alternate" type="text/html" title="Podcasts and blogs I‚Äôm following in early 2026" /><published>2026-01-02T19:13:35-07:00</published><updated>2026-01-02T19:13:35-07:00</updated><id>https://hpc.social/personal-blog/2026/podcasts-and-blogs-i-m-following-in-early-2026</id><content type="html" xml:base="https://hpc.social/personal-blog/2026/podcasts-and-blogs-i-m-following-in-early-2026/"><![CDATA[<p>As part of the new year, I&#8217;m going through my feed readers for podcasts and blogs. This is mostly a cleanup exercise to remove sources that I regularly skip, but I&#8217;m also adding in a few feeds for sites that I find myself regularly clicking on in social media. As part of this, I figured I&#8217;d share the sources that made the cut to stick around.</p>

<p><span id="more-377"></span></p>

<p>You&#8217;ll notice that there are a lot of podcasts in this post! With two golden doodles in the family, I spend a lot of time on dog walks, not to mention doing chores around the house. Because of this, it&#8217;s often a lot easier for me to listen to content than read it, and indeed I often find myself feeding long-form text articles into <a href="https://elevenreader.io/">ElevenReader</a> so that I can listen to those items too.</p>

<p><strong>Nerd notes:</strong></p>

<ul class="wp-block-list">
<li>I self-host <a href="https://freshrss.org/index.html">FreshRSS</a> to aggregate written blog feeds and read them using <a href="https://reederapp.com/">Reeder</a>. FreshRSS is hosted on a private VPS that I access via <a href="https://tailscale.com/">Tailscale</a> on my various devices, because I&#8217;m really the only person that needs to access it.</li>



<li>I listen to podcasts via <a href="https://overcast.fm/">Overcast</a>, which I prefer for its audio features to the default Apple Podcasts app.</li>



<li>This is not 100% complete as there are some blogs I follow purely through the Patreon site, and I haven‚Äôt (yet) taken the time to go through that and add them to this list.</li>



<li>There are a few NSFW items left out intentionally, as my voice on this blog is at least semi-professional <img alt="üòâ" class="wp-smiley" src="https://s.w.org/images/core/emoji/17.0.2/72x72/1f609.png" style="height: 1em;" /> </li>
</ul>

<h2 class="wp-block-heading">Computing-related</h2>

<p><strong>Podcasts:</strong></p>

<ul class="wp-block-list">
<li><em><a href="https://oxide-and-friends.transistor.fm/">Oxide and Friends</a></em> is a weekly live show recorded by Bryan Cantrill, Adam Leventhal, and friends from the <a href="https://oxide.computer">Oxide Computer Company</a>. Despite being a &#8220;corporate&#8221; podcast, it generally has the vibe of &#8220;Car Talk for Computers&#8221; and can often dig into really interesting computer systems topics, and even computer and industry history. Some of the episodes get into specifics of the Oxide product, which may be interesting or skip-able depending on your interests.</li>



<li><em><a href="https://www.fafo.fm/">Fork Around and Find Out</a></em> is a resurrection of the <em>Ship It!</em> podcast that used to be part of the Changelog network, focused on production systems, on-call, and large-scale engineering. The updates are a bit irregular but Justin and Autumn are enjoyable hosts to listen to.</li>



<li><em><a href="https://www.thisisfinepod.com/">This is Fine!</a></em> is a podcast on resilience engineering from Colette Alexander and Clint Byrum. It sometimes picks up topics from discussions in the <a href="https://resilienceinsoftware.org/">Resilience in Software Foundation Slack</a> instance and is almost always a fun listen.</li>



<li><em><a href="https://randsinrepose.com/the-important-thing/">The Important Thing</a> </em>is an occasional discussion podcast between <a href="https://randsinrepose.com/">Michael Lopp</a> and <a href="https://troxell.com/">Lyle Troxell</a>. Often very random, with widely varying episode lengths, it&#8217;s nicely chatty and a great listen during dog walks.</li>



<li><em><a href="https://signalsandthreads.com/">Signals and Threads</a></em>, from Jane Street, is another occasional podcast but often gets very deep into interesting software topics such as performance analysis, state machine replication, and memory management &#8212; with a focus on low-latency trading systems that have interesting constraints. </li>



<li><a href="https://changelog.com/podcast"><em>The Changelog</em></a> is a long-standing general software news podcast. I dip in and out of this one based on the topic being covered, and often like their &#8220;Changelog and Friends&#8221; chatty episodes more than the news or interview episodes.</li>



<li><em><a href="https://comparchpodcast.podbean.com/">The Compute Architecture Podcast</a></em> updates very infrequently but often has interesting, hardware- or systems-focused interviews.</li>
</ul>

<p><strong>Personal blogs:</strong></p>

<ul class="wp-block-list">
<li><a href="https://charity.wtf/">Charity Majors</a> is a long-time follow of mine for her technical work on observability, her practical SRE/sysadmin mentality, and her useful perspectives on engineering management.</li>



<li><a href="https://www.brendangregg.com/blog/">Brendan Gregg</a> posts infrequently, but will publish fascinating deep dives on performance engineering that are always worth reading.</li>



<li><a href="https://utcc.utoronto.ca/~cks/space/blog/">Chris Siebenmann</a> is a sysadmin at the University of Toronto and a prolific blogger about nuts-and-bolts Linux admin topics. He publishes a <em>ton</em> so I dip in and out of his feed, but always keep it in my feed reader.</li>



<li><a href="https://www.drcathicks.com/blog">Cat Hicks</a> does psychological research on software teams and I always learn a ton from her writing.</li>



<li><a href="https://soatok.blog/b/">Soatok</a> writes excellent, interesting, and opinionated articles on security and cryptography topics.</li>



<li><a href="https://ferd.ca/">Fred Hebert</a> is an SRE with a strong interest in resilience engineering who frequently discusses interesting academic research on resilience and human factors.</li>



<li><a href="https://blog.glennklockwood.com/">Glenn Lockwood</a> is an HPC engineer who I&#8217;ve known online for a long time, and who came into the field from materials science in a similar manner to me. He&#8217;s worked at SDSC, NERSC, Microsoft, and VAST, and his annual recap of the SuperComputing conference is worth reading every year. (So is the rest of his blog!)</li>



<li><a href="https://www.seangoedecke.com/">Sean Goedecke</a> is a software engineer at Github who writes interesting work on AI and on the dynamics of large companies.</li>



<li><a href="https://simonwillison.net/">Simon Willison</a> is one of the most essential bloggers on AI and LLMs today, not to mention incredibly prolific. His style of writing short posts on whatever he&#8217;s thinking about is one I hope to emulate more often here!</li>



<li>Rachel Kroll, aka <a href="https://rachelbythebay.com/w/">Rachel By the Bay</a>, is a long-time sysadmin/SRE who writes on detailed sysadmin and software engineering topics in an often-ironic fashion.</li>



<li><a href="https://xeiaso.net/blog/">Xe Iaso</a> is a software engineer and author of the <a href="https://anubis.techaro.lol/">Anubis</a> Web AI Firewall tool. Xer blog covers a wide variety of software, systems, and AI work.<br /></li>
</ul>

<p><strong>Technical blogs and industry news:</strong></p>

<ul class="wp-block-list">
<li><em><a href="https://lwn.net/">LWN</a></em> is the definitive source for Linux and free software news, and is supported by the community via subscriptions. You should subscribe!</li>



<li><em><a href="https://chipsandcheese.com/">Chips and Cheese</a></em> does really interesting deep dives into chip architecture and performance, often focused on newer products but occasionally digging into older hardware.</li>



<li><a href="https://semianalysis.com/"><em>SemiAnalysis</em></a> is at this point one of the most essential news sources for the semiconducting industry, and one of the few paid sources I follow.</li>



<li><em><a href="https://jepsen.io/blog">Jepsen</a></em> performs detailed analyses of distributed systems reliability and consistency by <a href="https://aphyr.com/">Kyle Kingsbury</a>, both as consulting engagements and for the community. Read all of these, they&#8217;re excellent!</li>



<li><em><a href="https://semiengineering.com/">Semiconductor Engineering</a></em> is one of the long-standing industry news sites. I don&#8217;t read a ton of this but I do keep an eye on the feed for interesting headlines.</li>



<li>Similarly, <em><a href="https://www.datacenterdynamics.com/en/">Data Center Dynamics</a></em> is one of the standard industry news sites for data centers.</li>
</ul>

<h2 class="wp-block-heading">News and Politics</h2>

<p><strong>Podcasts:</strong></p>

<ul class="wp-block-list">
<li><em><a href="https://www.lawfaremedia.org/podcasts-multimedia/podcast">The Lawfare Podcast</a></em> covers a really wide variety of national security law topics. My only regular listen is their <em><a href="https://www.lawfaremedia.org/podcasts-multimedia/podcast/rational-security">Rational Security</a></em> episodes which provide a weekly roundup of relevant news in an informal discussion format, but I dip in and out of the others.</li>



<li><em><a href="https://www.bloomberg.com/podcasts/series/money-stuff">Money Stuff</a></em> is a fun weekly podcast from Matt Levine and Katie Greifeld of Bloomberg News, who discuss weekly financial news from a very nerdy perspective. I&#8217;m not generally a huge finance person, but I like that this podcast allows me to listen in to people geeking out about the topic.</li>



<li><em><a href="https://www.economist.com/the-world-in-brief">The World in Brief</a></em> from the Economist is their daily quick summary of the news. I have very mixed feelings about the Economist in general &#8212; as with many British sources, they platform far too much transphobia &#8212; but I have yet to find a better substitute for &#8220;quick morning summary of the news&#8221;. At least, nothing else that doesn&#8217;t make me want to throw my phone at a wall.</li>
</ul>

<p><strong>Blogs and News:</strong></p>

<ul class="wp-block-list">
<li><em><a href="https://restofworld.org/">Rest of World</a></em> covers tech industry news with a focus on impacts outside the West, and often has really interesting coverage from a different angle.</li>



<li><em><a href="https://www.liberalcurrents.com/">Liberal Currents</a></em> is a political blog focused on liberalism, both in current events and as a political philosophy, and has published a lot of excellent pieces since I started reading it in 2025.</li>
</ul>

<h2 class="wp-block-heading">Miscellaneous</h2>

<p><strong>Podcasts:</strong></p>

<ul class="wp-block-list">
<li><a href="https://www.armscontrolwonk.com/archive/author/podcast/"><em>Arms Control Wonk</em></a> continues to be a good listen, though it&#8217;s updated something sporadically the past few years. The coverage of nuclear weapons, missiles and other delivery systems, and current events around arms control (or lack thereof) is very good. If you sponsor them via Patreon, their Slack instance is also a fascinating discussion forum, though I only dip in and out of it occasionally.</li>



<li><em><a href="https://culturestudypod.substack.com/">The Culture Study Podcast</a></em> by Anne Helen Petersen features conversations between Anne and a guest and focuses on listener Q&amp;A. It often covers culture topics that I otherwise don&#8217;t get much of through other feeds. For example, recent episodes have talked about anything from birding to K-pop to the anatomy of cultural panics. I don&#8217;t listen to every episode, but they&#8217;re often quite fun.</li>



<li><em><a href="https://www.liberalcurrents.com/neonliberalism/">Neon Liberalism</a></em> is a regular podcast from <a href="https://www.liberalcurrents.com/">Liberal Currents</a>. I might put this in the News category except that it often digs into political topics from a historical or theoretical perspective rather than just focusing on current events.</li>



<li>Similarly, <em><a href="https://open.spotify.com/show/29wW6zsYyYuelcFJcyHOmv">Reimagining Liberty</a></em> from Aaron Ross Powell digs into political theory and current events from the perspective of Powell&#8217;s particular strain of libertarian-ism, which is much more in conversation with modern liberalism and anarchism vs more right-wing strains.</li>
</ul>

<p><strong>Personal blogs:</strong></p>

<ul class="wp-block-list">
<li><a href="https://www.funraniumlabs.com/">Phil Broughton</a> is a health physicist at UC Berkeley who has worked in classified nuclear work at LLNL as well as spending a year in Alaska, and has a wealth of fascinating and hilarious stories.</li>



<li><a href="https://www.goodreads.com/author/show/16094.Lois_McMaster_Bujold/blog">Lois McMaster Bujold</a> is one of my favorite science fiction and fantasy authors. While she&#8217;s semi-retired, she still writes occasional novellas following Penric, a sorcerer in her World of the Five Gods, which I really love. Her blog helpfully announces new stories!</li>



<li><a href="https://whatever.scalzi.com/">John Scalzi</a> is another favorite author, and also has an excellent blog called <em>Whatever</em>.</li>



<li>Bret Devereaux writes <em><a href="https://acoup.blog/">A Collection of Unmitigated Pedantry</a></em> about history, the military, and pop culture. If you&#8217;re interested in an extensive deep dive into the military missteps made Saruman in <em>The Two Towers</em>, this is the blog for you!</li>



<li><em><a href="https://www.bitsaboutmoney.com/">Bits About Money</a></em> is Patrick McKenzie&#8217;s blog about finance, and each entry tends to be a highly-nerdy deep dive about how some interesting corner of the financial system works.</li>
</ul>

<p><strong>Webcomics:</strong></p>

<ul class="wp-block-list">
<li><em><a href="https://www.giantitp.com/comics/oots.html">The Order of the Stick</a></em> is a long-running D&amp;D stick-figure comic that I have been reading for longer than I can really say. I highly recommend it, though I&#8217;ll warn you that with an archive of &gt;1,300 comics (and growing!) you are likely to lose a lot of time this way.</li>



<li><em><a href="https://questionablecontent.net/">Questionable Content</a></em> is a slice-of-life comic about a coffee shop&#8230; with robots, super-intelligent AIs, stupid dick jokes, and more. Also has a long archive to dig through.</li>



<li><em><a href="https://www.girlgeniusonline.com/">Girl Genius</a></em> is a long-running online comic book about &#8220;Adventure, Romance, and MAD SCIENCE!&#8221; and thoroughly excellent.</li>
</ul>]]></content><author><name>Thinking Out Loud</name></author><category term="ajdecon" /><summary type="html"><![CDATA[As part of the new year, I&#8217;m going through my feed readers for podcasts and blogs. This is mostly a cleanup exercise to remove sources that I regularly skip, but I&#8217;m also adding in a few feeds for sites that I find myself regularly clicking on in social media. As part of this, I figured I&#8217;d share the sources that made the cut to stick around.]]></summary></entry><entry><title type="html">On Friday deploys</title><link href="https://hpc.social/personal-blog/2025/on-friday-deploys/" rel="alternate" type="text/html" title="On Friday deploys" /><published>2025-12-30T20:58:00-07:00</published><updated>2025-12-30T20:58:00-07:00</updated><id>https://hpc.social/personal-blog/2025/on-friday-deploys</id><content type="html" xml:base="https://hpc.social/personal-blog/2025/on-friday-deploys/"><![CDATA[<p><a href="https://charity.wtf/2025/12/24/on-friday-deploys-sometimes-that-puppy-needs-murdering-xpost/">This post</a> from Charity Majors on Friday deploys is well worth reading. </p>

<p>In the past I‚Äôve seen her comment on how deployments should be carried out fearlessly regardless of when, and I‚Äôve often felt like saying ‚Äúyeah, well, ‚Ä¶‚Äù. Because of course I agree with that as a goal, but many real-world orgs and conditions make it challenging.</p>

<p>This most recent post talks about the situations when those freezes <em>can</em> make sense, even if they‚Äôre not ideal. And in particular I like the discussion about what really needs to be frozen is not deploys, but merges:</p>

<blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow">
<p>To a developer, ideally, the act of merging their changes back to main and those changes being deployed to production should feel like one singular atomic action, the faster the better, the less variance the better. You merge, it goes right out. You don‚Äôt want it to go out, you better not merge.</p>




<p>The worst of both worlds is when you let devs keep merging diffs, checking items off their todo lists, closing out tasks, for days or weeks. All these changes build up like a snowdrift over a pile of grenades. You aren‚Äôt going to find the grenades til you plow into the snowdrift on January 5th, and then you‚Äôll find them with your face. Congrats!</p>

</blockquote>]]></content><author><name>Thinking Out Loud</name></author><category term="ajdecon" /><summary type="html"><![CDATA[This post from Charity Majors on Friday deploys is well worth reading.]]></summary></entry></feed>